# Machine Learning Projects and Experiments Repository

Welcome to my GitHub repository for machine learning projects and experiments! This repository contains a variety of Jupyter Notebook files showcasing different machine learning techniques, data analysis, and data engineering tasks. Feel free to explore the projects and experiments I've worked on.

## Table of Contents

1. [Anomaly Detection Using AutoEncoder with Pytorch](Anomaly_Detection_Using_AutoEncoder_with_Pytorch.ipynb)
   - Detect anomalies in data using an AutoEncoder model implemented with PyTorch.

2. [Bubble Detection for the Crypto Market](Bubble_Dedection_for_the_Crypto_Market.ipynb)
   - Analyze and detect bubbles in the cryptocurrency market using data analysis and visualization techniques.

3. [Data Engineering & Analysis](Data%20Engineering&Analysis.ipynb)
   - Perform data engineering tasks and exploratory data analysis to gain insights from various datasets.

4. [Depth Estimation 2D to 3D](Depth_Estimation_2D_to_3D.ipynb)
   - Convert 2D images to 3D depth maps using a machine learning approach.

5. [Feature Importance with XGBoost vs ppscore](Feature%20Importance%20with%20XGBoost%20vs%20ppscore.ipynb)
   - Compare feature importance techniques between XGBoost and ppscore libraries.

6. [Fine-Tune LLaMA 2 with QLoRA for QA Datasets](Fine_Tune_LLaMA_2_with_QLoRA_for_QA_Datasets.ipynb)
   - Fine-tune the LLaMA 2 model using QLoRA for question-answering datasets.

7. [Machine Learning Pipeline](Machine%20Learning%20Pipeline.ipynb)
   - Build a complete machine learning pipeline including preprocessing, model training, and evaluation.

8. [McKinsey ProHack Challenge 2020 with XGBoost](McKinsey%20ProHack%20Challange%202020%20xgboost%20with%20optimization.ipynb)
   - Participate in the McKinsey ProHack Challenge 2020 using XGBoost with optimization techniques.

9. [NLP Cases](NLP_Cases.ipynb)
   - Explore various natural language processing (NLP) cases and techniques.

10. [Quantize Llama 2.7B Model and Fine-Tune on QA Datasets](Quantize_Llama2_7B_model_and_Fine_Tune_on_QA_Datasets.ipynb)
    - Quantize the Llama 2.7B model and fine-tune it on question-answering datasets.

11. [Quantum Method for Portfolio Optimization](Quantum_Method_for_Portfolio_Optimizationipynb.ipynb)
    - Utilize a quantum approach for portfolio optimization.

12. [Rule-Based Turkish Language Sentiment Analysis](Rule%20Based%20Turkish%20Language%20Sentiment%20Analysis.ipynb)
    - Perform sentiment analysis on Turkish text using a rule-based approach.

13. [SARIMA Model](Sarima%20Model.ipynb)
    - Build a Seasonal Autoregressive Integrated Moving Average (SARIMA) model for time series forecasting.

14. [Turkey Conflicts Data Mining](Turkey%20Conflicts%20Data%20Mining.ipynb)
    - Mine and analyze data related to conflicts in Turkey.

15. [Turkish Text Classification](Turkish%20Text%20Classification.ipynb)
    - Perform text classification on Turkish text using machine learning techniques.

16. [Vector Databases Tutorial](VectorDatabasesTutorial.ipynb)
    - Tutorial on working with vector databases in the context of machine learning.

17. [Llama 2.13B Playground](llama_cpp_python__Llama_2_13b_playground.ipynb)
    - Experiment and explore the Llama 2.13B model.

18. [Medical Trends Analysis](medical_trends.ipynb)
    - Analyze trends in medical data.

19. [Portfolio Optimization](portfolio_opt.ipynb)
    - Optimize investment portfolios using machine learning techniques.

20. [Stroke Classification](stroke_not_stroke_classification.ipynb)
    - Classify stroke and non-stroke cases using machine learning.

21. [Tapu Kadastro Analysis](tapu_kadastro.ipynb)
    - Analyze tapu (land registry) and kadastro (cadastre) data.

## Requirements

The project notebooks are implemented using various libraries and frameworks. To reproduce the results or run the notebooks, please refer to the [`requirements.txt`](requirements.txt) file for the necessary dependencies.

Feel free to reach out if you have any questions or suggestions. Happy exploring and learning!

**Note:** Some notebooks were created using Colaboratory, and others were developed locally. Make sure you have the required libraries and packages installed before running the notebooks.
